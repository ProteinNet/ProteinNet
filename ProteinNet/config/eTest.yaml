experiment_name: Test                   # The name of experiment

seed: 0
dataset: mane
num_workers: 8
batch_size: 32                          # batch size
graph_encoder_type: GAT                 # GNN backbone (GCN, GAT, SAGE, GIN)

warm_up: 10                             # warm-up epochs
epochs: 100                             # total number of epochs
init_lr: 0.0001                         # initial learning rate for Adam (default=0.0005)
weight_decay: 1e-5                      # weight decay for Adam
log_every_n_steps: 10                   # print training log frequency
gpu: cuda:0                             # training GPU 

embed: 
  init_node_dim: 8                      # Initial Node Embedding Dimension.
  init_edge_dim: 4                      # Initial Edge Embedding Dimension.

graph_encoder: 
  num_layers: 5                         # number of graph conv layers
  hidden_dim: 32                        # Hidden Node Dimension.
  drop_ratio: 0.0                       # Dropout Ratio.

loss:
  temperature: 1.0                      # temperature of NT-Xent loss
  use_cosine_similarity: True           # whether to use cosine similarity in NT-Xent loss (i.e. True/False)

finetune:
  seed: 0
  task: dna                             # dna, atp
  batch_size: 64
  isTAPE: False                         # Use TAPE encoding or not.
  num_workers: 8
  pretrained_model_dir: None
  output_model_dir : None               # Should make 'None' to save pretrain.
  init_lr: 0.001
  weight_decay: 1e-5
  epochs: 100
